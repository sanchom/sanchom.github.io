<html>
  <head>
    <title>Sancho McCann</title>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,600,700" rel="stylesheet">
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.blue-light_blue.min.css" />
    <script defer src="https://code.getmdl.io/1.3.0/material.min.js"></script>

    <style>
      .page-content {
      padding-left: 20%;
      padding-right: 20%;
      padding-top: 80px;
      padding-bottom: 80px;
      }

      .card-wide.mdl-card {
      margin-top: 30px;
      width: 100%;
      }

      img.align-left {
      float: left;
      margin: 0 1em 1em 0;
      }
    </style>
  </head>
  <body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header">
      <header class="mdl-layout__header">
        <div class="mdl-layout__header-row">
          <!-- Title -->
          <span class="mdl-layout-title">Sancho McCann</span>
          <!-- Add spacer, to align navigation to the right -->
          <div class="mdl-layout-spacer"></div>
          <!-- Navigation. We hide it in small screens. -->
          <nav class="mdl-navigation mdl-layout--large-screen-only">
            <a class="mdl-navigation__link" href="#publications">Publications</a>
            <a class="mdl-navigation__link" href="#projects">Projects</a>
            <a class="mdl-navigation__link" href="#resume">Resume</a>
            <a class="mdl-navigation__link" href="http://sanchom.wordpress.com">Blog (bye)</a>
          </nav>
        </div>
      </header>
      <main class="mdl-layout__content">
        <div class="page-content">
          <p>I finished my PhD at the University of British Columbia in April 2014, supervised by <a rel="nofollow" href="http://www.cs.ubc.ca/~lowe/">David Lowe</a>. My professional interests are scene understanding and object recognition, including machine learning and applications of convolutional neural networks.</p>

          <a name="publications"></a>
          <div class="card-wide mdl-card mdl-shadow--2dp">
            <div class="mdl-card__title mdl-card--border">
              <h2 class="mdl-card__title-text" name="publications">Selected Publications</h2>
            </div>
            <div class="mdl-card__supporting-text">
              <h4>Thesis</h4>
              <p>Sancho McCann. "Object classification and localization using spatially localized features". PhD Dissertation. UBC Department of Computer Science. 2014.</p>
              <h4>Journal papers</h4>
              <p>David Meger, Per-Erik. Forssén, Kevin Lai, Scott Helmer, Sancho McCann, Tristram Southey, Matthew Baumann, James J. Little, and David G. Lowe. "Curious George: An Attentive Semantic Robot". In <em>Robotics and Autonomous Systems Journal</em>, Volume 56, Number 6, pp. 503—511. June 2008. [<a rel="nofollow" href="http://www.cs.ubc.ca/labs/lci/curious_george/pubs/UBC_RAS_FSHSC.pdf">pdf</a>]</p>
              <h4>Conference papers</h4>
              <p>Sancho McCann and David G. Lowe. "Spatially Local Coding for Object Recognition." <em>ACCV</em>, 2012. [<a href="assets/McCannLowe_ACCV2012_0851.pdf">pdf</a>][<a href="assets/McCannLowe_ACCV2012_0851_poster.pdf">poster</a>][<a href="http://www.cs.ubc.ca/projects/spatially-local-coding">project page</a>]</p>
              <p>Sancho McCann and David G. Lowe. "Local Naive Bayes Nearest Neighbor for Image Classification." <em>CVPR</em>, 2012. [<a href="assets/McCannLowe_CVPR2012_1925.pdf">pdf</a>] [<a href="http://www.cs.ubc.ca/projects/local-nbnn">project page</a>]</p>
              <p>David Meger, Per-Erik Forssén, Kevin Lai, Scott Helmer, Sancho McCann, Tristram Southey, Matthew Baumann, James J. Little, David G. Lowe and Bruce Dow. "Curious George: An Attentive Semantic Robot." <em>IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2007 Workshop: From sensors to human spatial concepts, </em>November, 2007. [<a rel="nofollow" href="http://www.cs.ubc.ca/~perfo/abstracts/meger07.html">pdf</a>]</p>
              <p>Sancho McCann and Jacky Baltes. "Towards Automatic Image Modification as an Empirical Test of Image Segmentation." In <em>Proc. 9th International Conference on Control, Automation, Robotics and Vision (ICARCV),</em> 2006. [<a title="McCannBaltes - Towards Automatic Image Modification.pdf" href="assets/McCannBaltes_-_Towards_Automatic_Image_Modification.pdf">pdf</a>]</p>
              <p>Sancho McCann and Jacky Baltes. "Abarenbou – A Small Vision-Based Humanoid Robotic Research platform." In <em>Proc. of the Third International Conference on Computational Intelligence, Robotics, and Autonomous Systems (CIRAS), </em>2005. [<a title="McCannBaltes - Abarenbou.pdf" href="assets/McCannBaltes-Abarenbou.pdf">pdf</a>]</p>
              <h4>Other publications</h4>
              <p><a href="https://scholar.google.com/citations?user=6C-udIUAAAAJ">Google Scholar Profile</a></p>
              <p>
            </div>
          </div>
          
          <a name="projects"></a>
          <div class="card-wide mdl-card mdl-shadow--2dp">
            <div class="mdl-card__title mdl-card--border">
              <h2 class="mdl-card__title-text">Projects</h2>
            </div>
            <div class="mdl-card__supporting-text mdl-card--border">
              <h4>Spatially local coding</h4>
              <p><a href="assets/toptens.png"><img src="assets/toptens-150x150.png" alt="Visualization of features" title="Spatially local coding visualization" width="150" height="150" class="align-left" /></a> The spatial pyramid and its variants have been among the most popular and successful models for object recognition. To create a spatial pyramid representation of an image, you need to encode local visual features as elements of a visual vocabulary and then pool these encoded features into histograms at several spatial granularities. In this project, we introduce spatially local coding, an alternative way to include spatial information in the image model. Instead of only coding visual appearance and leaving the spatial coherence to be represented by the pooling stage, we include location as part of the coding step. This is a more flexible spatial representation as compared to the fixed grids used in the spatial pyramid models and we can use a simple, whole-image region during the pooling stage. On the Caltech 101 and 256 object recognition datasets, this model performs better than all previous single-feature methods.</p>
              <p>More details, code: [<a href="http://www.cs.ubc.ca/projects/spatially-local-coding">Project page</a>]</p>
              <p>Sancho McCann and David G. Lowe. "Spatially Local Coding for Object Recognition." <em>ACCV</em>, 2012. [<a href="assets/McCannLowe_ACCV2012_0851.pdf">pdf</a>][<a href="assets/McCannLowe_ACCV2012_0851_poster.pdf">poster</a>]</p>
              
            </div>

            <div class="mdl-card__supporting-text mdl-card--border">
              <h4>Local Naive Bayes Nearest Neighbor</h4>
              <p><a href="assets/Manifold-e1333591359916.png"><img src="assets/Manifold-e1333591359916-150x150.png" alt="" title="Local Naive Bayes Nearest Neighbor" width="150" height="150" class="align-left" /></a> Local Naive Bayes Nearest Neighbor improves upon the NBNN image classification algorithm. It increases classification accuracy and allows NBNN to scale to large numbers of object classes. We observed that in NBNN, only the classes with features in the local neighborhood of a descriptor get significant and reliable updates to their posterior probabilities. Instead of maintaining a separate search structure for each class, we merge all of the reference data together into one search structure, allowing quick identification of a descriptor's local neighborhood across all classes. By ignoring adjustments to the more distant classes, local NBNN gives higher classification accuracy and its run time grows with the log of the number of classes rather than linearly. This gives a 100 times speed-up over original NBNN on the Caltech 256 dataset. We also show the first head-to-head comparisons of NBNN against spatial pyramid methods using a common set of input features. We found that local NBNN outperforms all previous NBNN based methods and the original spatial pyramid model. However, local NBNN does not beat state-of-the-art spatial pyramid methods that use local soft assignment and max-pooling.</p>
              <p>More details, code: [<a href="http://www.cs.ubc.ca/projects/local-nbnn">Project page</a>]</p>
              <p>Sancho McCann and David G. Lowe. "Local Naive Bayes Nearest Neighbor for Image Classification." <em>CVPR</em>, 2012. [<a href="assets/McCannLowe_CVPR2012_1925.pdf">pdf</a>]</p>
              <p>Sancho McCann and David G. Lowe. "Local Naive Bayes Nearest Neighbor for Image Classification", <em>Technical Report TR-2011-11, Department of Computer Science, University of British Columbia</em>, 2011. [<a href="http://www.cs.ubc.ca/cgi-bin/tr/2011/TR-2011-11">@ UBC</a>] [<a href="http://arxiv.org/abs/1112.0059">@ arXiv</a>]</p>
              <p>Sancho McCann and David G.  Lowe. "Object Categorization Using Sparse Nearest Neighbor Distances for Improved Accuracy and Scalability", <em>1st IEEE Workshop on Kernels and Distances for Computer Vision</em>, 2011. [<a href='assets/McCannLowe-SparseNearestNeighbors.pdf'>poster</a>]</p>
            </div>
            
            <div class="mdl-card__supporting-text mdl-card--border">
              <h4>Humanoid Robot</h4>
              <p><a href="assets/abarenbou.png"><img class="align-left" title="abarenbou" src="assets/abarenbou-225x300.png" alt="" width="150" height="200" /></a>I worked with <a href="http://www.cs.umanitoba.ca/~jacky/">Dr. Jacky Baltes</a> on a small-size humanoid robot named Abarenbou. The vision system used a camera detached from an early Sony Clié. All processing was done on the Sony Clié. We coded in C and cross compiled for the ARM processor. I developed a rule-based behaviour system for finding, approaching, and kicking the ball. I manually tuned the walking gait using custom software. Abarenbou was our entry in the 2005 FIRA RoboWorld Cup.</p>
              <p>Sancho McCann and Jacky Baltes. "Abarenbou – A Small Vision-Based Humanoid Robotic Research platform." In <em>Proc. of the Third International Conference on Computational Intelligence, Robotics, and Autonomous Systems (CIRAS), </em>2005. [<a title="McCannBaltes - Abarenbou.pdf" href="assets/McCannBaltes-Abarenbou.pdf">pdf</a>]</p>
            </div>

            <div class="mdl-card__supporting-text mdl-card--border">
              <h4>Robot Airplane</h4>
              <p><a href="assets/airplane.png"><img class="align-left" title="airplane" src="assets/airplane.png" alt="" width="150" /></a>During my last term at the University of Manitoba, a small group of us assembled to form the Unmanned Aerial Vehicle team. We prepared an entry to the Association for Unmanned Vehicle Systems International's student competition. Our goal was to have our airplane take-off, fly a search pattern, and land. All autonomously. While in the search area, a video feed was fed to an ground-based observing station, where an observer was to mark targets of interest and report their coordinates. Grading was based on accomplishing the mission autonomously, and the accuracy of our coordinates. We found good teammates, advisors, and sponsors. We placed 1st out of 17 teams in a field that included BYU, University of Texas, Cornell, MIT, and UCSD. I wrote much of the computer vision code, transforming the video's pixel coordinates to GPS coordinates, and giving that information to the observer in an easy to use interface.</p>
              <p>Paul Furgale, Sancho McCann, Jim Majewski, Andrew Bugera, and Kory Zelickson. "Team Manitoba 2006 AUVSI Student Competition Project Description." <em>Association for Unmanned Vehicle Systems International (AUVSI): 4th Annual Student Unmanned Aerial Vehicle Competition,</em> Lexington Park, MD, 2006 [<a title="TeamManitoba - AUVSI 2006.pdf" href="assets/TeamManitoba2006.pdf">pdf</a>]</p>
            </div>
            
            <div class="mdl-card__supporting-text mdl-card--border">
              <h4>AtmosView: Visualization Redesign</h4>
              <p><a href="assets/Screen-shot-2011-08-07-at-9.22.51-AM.png"><img class="align-left" title="atmosview" src="assets/Screen-shot-2011-08-07-at-9.22.51-AM.png" alt="" width="150" /></a>I created AtmosView, a re-design of the visualization of atmospheric sounding data. Relationships between temperature, dewpoint, and the lifting of imaginary parcels of air are important to the determination of soaring conditions, atmospheric stability, and likelihood of severe weather. The current diagrams to display these relationships have been described as the most difﬁcult atmospheric diagrams to read. The re-design applies well tested information visualization principles to expose data to the user previously hidden behind lines and frames. This not only improves extraction of data from individual charts, but allows for easier comparison between multiple charts. An informal evaluation of the re-design was encouraging and with some further work, a system designed around the AtmosView visualization should become usable for people with an amateur interest in these meteorological relationships.</p>
              <p>Sancho McCann. "Atmospheric Sounding Visualization." Project report. [<a href="assets/McCann-AtmosView.pdf">pdf</a>]</p>
            </div>
            
          </div>

          <a name="resume"></a>
          <div class="card-wide mdl-card mdl-shadow--2dp">
            <div class="mdl-card__title mdl-card--border">
              <h2 class="mdl-card__title-text" name="publications">Resume</h2>
            </div>
            <div class="mdl-card__supporting-text">

              <h4>Education</h4>
              <p style="padding-left: 30px;">Ph.D. (Computer Science), University of British Columbia — 2014</p>
              <h4>Languages and Technologies</h4>
              <p style="padding-left: 30px;">Python: 2.x, NumPy, SciPy, Matplotlib, Cython</p>
              <p style="padding-left: 30px;">C/C++: C++11, Boost, Google Test, Protocol Buffers, Apache Thrift</p>
              <p style="padding-left: 30px;">Scala: Play 2.x, Slick</p>
              <p style="padding-left: 30px;">Computer vision: Custom algorithm research, design, implementation, evaluation. OpenCV. Convolutional and recurrent neural networks using Caffe, Torch, TensorFlow.</p>
              <h4>Employment</h4>
              <h5>Research Assistant, University of Manitoba — 2005</h5>
              <p style="padding-left: 30px;">I worked with Dr. Jacky Baltes in the Autonomous Agents Laboratory on a small, humanoid robot. I wrote vision algorithms and developed a stable walking gait for the robot.</p>
              <h5>Research and Development, Frantic Films — 2006</h5>
              <p style="padding-left: 30px;">I did production work for <em>Superman Returns</em> and software development for their rendering pipeline.</p>
              <h5>Software Engineer Intern, Google — 2010, 2011</h5>
              <p style="padding-left: 30px;">In 2010, I helped develop a prototype Android application with the Geo/Street View team.</p>
              <p style="padding-left: 30px;">In 2011, I worked on improving the automatic organization of YouTube data.</p>
              <h5>Head of Research and Development, Shelfie — 2014-2017</h5>
              <p style="padding-left: 30px;">Shelfie was an app that automatically identified books in photos
                that our users took of their bookshelves. We used that information to help people find the next book they might want to read and to give them free
                eBook versions of their paper books. I wrote most of the automatic recognition system, including feature-based nearest-neighbor matching,
                text-recognition, and convolutional neural networks. I created custom validation datasets and tools for quality control 
                pre-release and in production. I managed our SRED and IRAP projects, drafted patent applications, and mentored teammates when they helped with this research.
              </p>
              <h4>Leadership, Volunteering, Hobbies</h4>
              <p style="padding-left: 30px;">I have a Commercial Pilot Licence and a Class 1 Flight Instructor Rating. I got most of my flight experience as a flight instructor at Flying Colors Pilot Training and flew with their precision flight team. I've also delivered flight training to Canadian Forces pilots taking their Primary Flight Training and have held a Class 2 Aerobatic Flight Instructor rating. I won the <a href="http://www.flying-colors.org/WEBSTER-NEWS-RELEASE.html">John C. Webster Memorial Trophy</a>. Today, I stay current by flying recreationally around the lower mainland of British Columbia.</p>
              <p style="padding-left: 30px;">I was a member of the Canadian Forces in the Cadet Instructor Cadre. I helped administer the training of the Royal Canadian Air Cadets. My duties included organizing training programs, supervision and development of instructors, administrative work, and many ad-hoc leadership roles. I've developed and taught an introductory level aviation course.</p>
              <p style="padding-left: 30px;">During my time at UBC, I held several volunteer roles in the Department of Computer Science at UBC. I led activities for TechTrek and GirlSmarts, two outreach programs the department organizes. I was a member of the department's recruiting and admissions committee. I've mentored a junior TA and helped develop and deliver the TA training program. I was the president of the Computer Science Graduate Student Association. I was a councilor representing the computer science graduate students in UBC's Graduate Student Society.</p>
              <p style="padding-left: 30px;">I played competitive ultimate and held leadership roles with UBC Ultimate, Refinery, and Blackfish. I'm an amateur short-distance sprinter.</p>
            </div>
          </div>
          
        </div>
      </main>
    </div>
    
  </body>
</html>
