<html>
  <head>
    <!-- Global Site Tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-106592360-1"></script>
    <script>
       window.dataLayer = window.dataLayer || [];
       function gtag(){dataLayer.push(arguments)};
       gtag('js', new Date());

       gtag('config', 'UA-106592360-1');
    </script>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Sancho McCann</title>
    <link href="https://fonts.googleapis.com/css?family=Lora:400,700|Noto+Serif:400,400i,700,700i" rel="stylesheet">
    <style>
      @media all {html {font-size: 24px;}}
      @media all and (max-width:800px){html {font-size: 24px;}}
      @media all and (max-width:760px){html {font-size: 23px;}}
      @media all and (max-width:720px){html {font-size: 22px;}}
      @media all and (max-width:680px){html {font-size: 21px;}}
      @media all and (max-width:640px){html {font-size: 20px;}}
      @media all and (max-width:600px){html {font-size: 19px;}}
      @media all and (max-width:560px){html {font-size: 18px;}}
      @media all and (max-width:520px){html {font-size: 17px;}}
      @media all and (max-width:480px){html {font-size: 16px;}}

      body {
      font-feature-settings: "liga" 1, "kern" 1;
      text-rendering: optimizeLegibility;
      font-family: 'Noto Serif', serif;
      margin: 0em;
      padding: 0;
      max-width: 800px;
      margin-top: 3em;
      margin-left: auto;
      margin-right: auto;
      padding-left: 2em;
      padding-right: 2em;
      }
      
      a { color: #37b; text-decoration: none;}
      
      img { float: left; margin-right: 1em; margin-bottom: 1em;}
      h1, h2, h3, h4, h5, h6 {
      font-family: 'Lora', serif; 
      clear: left;
      font-weight: bolder;
      padding-top: 0.2em;
      margin-top: 3em;
      margin-bottom: 0.3em;
      margin-left: -1em;
      }
      h1, h2 {
      border-top: 2px solid #ddd;
      }
      h1 { margin-top: 0; font-size: 120%; }
      h2 { font-size: 110%; }
      h3 { font-size: 100%; }
      h4 { font-size: 100%; }
      h5 { font-size: 100%; }
      h6 { font-size: 100%; }
      p, li { line-height: 130% }
    </style>
  </head>
  <body>
    <p>I am a computer scientist interested in object recognition, machine learning, and applications of deep neural networks. I finished my Ph.D. at the University of British Columbia in April 2014 and was supervised by <a rel="nofollow" href="http://www.cs.ubc.ca/~lowe/">David Lowe</a>. </p>

    <h2>Selected Publications</h2>
    <p>Sancho McCann. &ldquo;Object classification and localization using spatially localized features&rdquo;. Ph.D. Dissertation. UBC Department of Computer Science. 2014. [<a href="https://open.library.ubc.ca/media/download/pdf/24/1.0167312/1">pdf</a>]</p>
    <p>Sancho McCann and David G. Lowe. &ldquo;Spatially Local Coding for Object Recognition.&rdquo; <em>ACCV</em>, 2012. [<a href="assets/McCannLowe_ACCV2012_0851.pdf">pdf</a>][<a href="assets/McCannLowe_ACCV2012_0851_poster.pdf">poster</a>][<a href="http://www.cs.ubc.ca/projects/spatially-local-coding">project page</a>]</p>
    <p>Sancho McCann and David G. Lowe. &ldquo;Local Naive Bayes Nearest Neighbor for Image Classification.&rdquo; <em>CVPR</em>, 2012. [<a href="assets/McCannLowe_CVPR2012_1925.pdf">pdf</a>] [<a href="http://www.cs.ubc.ca/projects/local-nbnn">project page</a>]</p>
    <p>David Meger, Per-Erik. Forssén, Kevin Lai, Scott Helmer, Sancho McCann, Tristram Southey, Matthew Baumann, James J. Little, and David G. Lowe. &ldquo;Curious George: An Attentive Semantic Robot&rdquo;. In <em>Robotics and Autonomous Systems Journal</em>, Volume 56, Number 6, pp. 503–511. June 2008. [<a rel="nofollow" href="http://www.cs.ubc.ca/labs/lci/curious_george/pubs/UBC_RAS_FSHSC.pdf">pdf</a>]</p>
    <p>Sancho McCann and Jacky Baltes. &ldquo;Towards Automatic Image Modification as an Empirical Test of Image Segmentation.&rdquo; In <em>Proc. 9th International Conference on Control, Automation, Robotics and Vision (ICARCV),</em> 2006. [<a title="McCannBaltes - Towards Automatic Image Modification.pdf" href="assets/McCannBaltes_-_Towards_Automatic_Image_Modification.pdf">pdf</a>]</p>
    <p>Sancho McCann and Jacky Baltes. &ldquo;Abarenbou – A Small Vision-Based Humanoid Robotic Research platform.&rdquo; In <em>Proc. of the Third International Conference on Computational Intelligence, Robotics, and Autonomous Systems (CIRAS), </em>2005. [<a title="McCannBaltes - Abarenbou.pdf" href="assets/McCannBaltes-Abarenbou.pdf">pdf</a>]</p>
    <p>A more complete list is at my <a href="https://scholar.google.com/citations?user=6C-udIUAAAAJ">Google Scholar profile</a>.</p>
    
    <h2>Projects</h2>
    <h4>Spatially local coding</h4>
    <p><a href="assets/toptens.png"><img src="assets/toptens-150x150.png" alt="Visualization of features" title="Spatially local coding visualization" width="150" height="150" /></a> This method for classifying images takes features that have been extracted from a training dataset and groups them into clusters that are similar in appearance and location.</p>
    <p>More details, code: [<a href="http://www.cs.ubc.ca/projects/spatially-local-coding">Project page</a>]</p>

    <h4>Local Naive Bayes Nearest Neighbor</h4>
    <p><a href="assets/Manifold-e1333591359916.png"><img src="assets/Manifold-e1333591359916-150x150.png" alt="" title="Local Naive Bayes Nearest Neighbor" width="150" height="150" /></a> Local Naive Bayes Nearest Neighbor improves upon the NBNN image classification algorithm. Local NBNN gives higher classification accuracy and runs 100 times faster than NBNN on the Caltech 256 dataset.</p>
    <p>More details, code: [<a href="http://www.cs.ubc.ca/projects/local-nbnn">Project page</a>]</p>
            
    <h4>Humanoid Robot</h4>
    <p><a href="assets/abarenbou.png"><img title="abarenbou" src="assets/abarenbou-225x300.png" alt="" width="150" height="200" /></a>I worked with <a href="http://www.cs.umanitoba.ca/~jacky/">Dr. Jacky Baltes</a> to build a small-size humanoid robot. I coded in C and cross compiled for the ARM processor on a Sony Clie. I programmed it to walk and to find and kick a ball. This was our entry in the 2005 FIRA RoboWorld Cup.</p>
    <p>Sancho McCann and Jacky Baltes. &ldquo;Abarenbou – A Small Vision-Based Humanoid Robotic Research platform.&rdquo; In <em>Proc. of the Third International Conference on Computational Intelligence, Robotics, and Autonomous Systems (CIRAS), </em>2005. [<a title="McCannBaltes - Abarenbou.pdf" href="assets/McCannBaltes-Abarenbou.pdf">pdf</a>]</p>

    <h4>Robot Airplane</h4>
    <p><a href="assets/airplane.png"><img title="airplane" src="assets/airplane.png" alt="" width="150" /></a>At the University of Manitoba, I was part of a team that built a robot airplane that could take-off, fly a search pattern, and land&mdash;all autonomously. The airplane sent a video feed and telemetry to a ground station, where one of our teammates could mark targets of interest and report their coordinates. We placed first out of seventeen teams in a competition that included BYU, University of Texas, Cornell, MIT, and UCSD. I wrote much of the computer vision code, which transformed the video feed&rsquo;s pixel coordinates into GPS coordinates, and presented that information to our ground station&rsquo;s operator.</p>
    <p>Paul Furgale, Sancho McCann, Jim Majewski, Andrew Bugera, and Kory Zelickson. &ldquo;Team Manitoba 2006 AUVSI Student Competition Project Description.&rdquo; <em>AUVSI: 4th Annual Student Unmanned Aerial Vehicle Competition,</em> 2006 [<a title="TeamManitoba - AUVSI 2006.pdf" href="assets/TeamManitoba2006.pdf">pdf</a>]</p>
            
    <h4>AtmosView: Visualization Redesign</h4>
    <p><a href="assets/Screen-shot-2011-08-07-at-9.22.51-AM.png"><img title="atmosview" src="assets/Screen-shot-2011-08-07-at-9.22.51-AM.png" alt="" width="150" /></a>I created AtmosView, a new visualization for atmospheric sounding data (vertical profiles of the atmosphere&rsquo;s temperature and humidity). People use this data to predict soaring conditions, atmospheric stability, and the likelihood of severe weather. Previous diagrams have been called the most difficult atmospheric diagrams to read. AtmosView helps readers see this information on individual charts, and allows them to more easily compare between multiple charts.</p>
    <p>Sancho McCann. &ldquo;Atmospheric Sounding Visualization.&rdquo; Project report. [<a href="assets/McCann-AtmosView.pdf">pdf</a>]</p>

    <h2 name="publications">Résumé</h2>

    <h4>Languages, libraries, and tools</h4>
    <p>Python: 2/3, NumPy, SciPy, Matplotlib, Cython</p>
    <p>C/C++: C++11/14, Boost, Google Test, Protocol Buffers, Apache Thrift</p>
    <p>Scala: Play 2.x, Slick</p>
    <p>Computer vision: Custom algorithm research, design, implementation, evaluation. OpenCV. Convolutional and recurrent neural networks using Caffe, Torch, TensorFlow.</p>
    <h4>Research Assistant, University of Manitoba — 2005</h4>
    <p>I worked with Dr. Jacky Baltes in the Autonomous Agents Laboratory on a small, humanoid robot. I wrote vision algorithms and developed a stable walking gait for the robot.</p>
    <h4>Research and Development, Frantic Films — 2006</h4>
    <p>I did production work for <em>Superman Returns</em> and software development for their rendering pipeline.</p>
    <h4>Software Engineer Intern, Google — 2010, 2011</h4>
    <p>In 2010, I helped develop a prototype Android application with the Geo/Street View team.</p>
    <p>In 2011, I worked on improving the automatic organization of YouTube data.</p>
    <h4>Head of Research and Development, Shelfie — 2014-2017</h4>
    <p>Shelfie was an app that automatically identified books in photos
      that our users took of their bookshelves. I wrote most of the automatic recognition system, including feature-based nearest-neighbor matching,
      text-recognition, and convolutional neural networks. I created custom validation datasets and tools for quality control. I managed our SRED and IRAP projects, drafted patent applications, and mentored teammates when they helped with this research.
    </p>
    <h4>Leadership, volunteering, hobbies</h4>
    <p>I have a Commercial Pilot Licence and a Class 1 Flight Instructor Rating. I got most of my flight experience as a flight instructor at Flying Colors Pilot Training and flew with their precision flight team. I&rsquo;ve also delivered flight training to Canadian Forces pilots taking their Primary Flight Training and have held a Class 2 Aerobatic Flight Instructor rating. I won the <a href="http://www.flying-colors.org/WEBSTER-NEWS-RELEASE.html">John C. Webster Memorial Trophy</a>. Today, I stay current by flying recreationally around the lower mainland of British Columbia.</p>
    <p>I was a member of the Canadian Forces in the Cadet Instructor Cadre. My duties included organizing training programs, supervision and development of instructors, administrative work, and many ad-hoc leadership roles. I&rsquo;ve developed and taught an introductory level aviation course.</p>
    <p>During my time at UBC, I held several volunteer roles in the Department of Computer Science at UBC. I led activities for outreach programs, I was a member of the department&rsquo;s recruiting and admissions committee, and I&rsquo;ve helped deliver the TA training program. I was the president of the Computer Science Graduate Student Association and I was a councilor representing the computer science graduate students in UBC&rsquo;s Graduate Student Society.</p>
    <p>I am the volunteer webmaster for the Webster Memorial Trophy Competition. I manage the technical setup of their website and also do some copywriting.</p>
    <p>I played competitive ultimate and held leadership roles with UBC Ultimate, Refinery, and Blackfish. I&rsquo;m an <a href="http://athletics.ca/wp-content/themes/default-bs3/popups/athlete-rankings.php?id=8218097&year=0">amateur short-distance sprinter</a>.</p>
  </body>
</html>
